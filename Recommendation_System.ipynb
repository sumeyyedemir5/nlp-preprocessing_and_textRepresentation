{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPQusQHmrAmhKWC8ZU5ylZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumeyyedemir5/nlp-preprocessing_and_textRepresentation/blob/main/Recommendation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommendation system - Neural Network"
      ],
      "metadata": {
        "id": "N1ZErLGwKUzZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSbYzp0s1-oT"
      },
      "outputs": [],
      "source": [
        "# Recommendation system : kullanıcılara geçmiş davranışlarına, tercihlerine dayalı analizlerle\n",
        "# ilgilerini çekebilecek hizmetler önermek için kullanılan sistemdir.\n",
        "!pip install tensorflow\n",
        "#import libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veri seti\n",
        "user_ids =  np.array([0,1,2,3,4,0,1,2,3,4])\n",
        "item_ids = np.array([0,1,2,3,4,1,2,3,4,5])\n",
        "ratings =  np.array([5,4,3,2,1,4,5,2,3,4])\n"
      ],
      "metadata": {
        "id": "9jv_ZDg19CBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "\n",
        "user_id_train, user_id_test , item_id_train, item_id_test , rating_train, rating_test = train_test_split(\n",
        "    user_ids, item_ids, ratings, test_size = 0.2,random_state =42)\n",
        "\n"
      ],
      "metadata": {
        "id": "YCDC9ajY93YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create NN model\n",
        "num_users = 5\n",
        "num_items = 6\n",
        "\n",
        "def create_model(num_users, num_items, embedding_dim):\n",
        "  user_input = Input(shape=(1,),name=\"user\")\n",
        "  item_input = Input(shape=(1,),name=\"item\")\n",
        "\n",
        "  user_embedding = Embedding(input_dim = num_users, output_dim = embedding_dim, name=\"user_embedding\")(user_input)\n",
        "  item_embedding = Embedding(input_dim = num_items, output_dim = embedding_dim, name=\"item_embedding\")(item_input)\n",
        "\n",
        "  user_vec = Flatten()(user_embedding)\n",
        "  item_vec = Flatten()(item_embedding)\n",
        "\n",
        "  dot_product = Dot(axes=1)([user_vec, item_vec])\n",
        "  output = Dense(1)(dot_product)\n",
        "\n",
        "  model = Model(inputs = [user_input,item_input], outputs = output)\n",
        "\n",
        "  model.compile(optimizer = Adam(learning_rate=0.01),loss=\"mean_squared_error\")\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "uL1iXhRn_ErF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training NN model\n",
        "embedding_dim = 8 # 8 boyutlu\n",
        "model = create_model(num_users, num_items, embedding_dim)\n",
        "model.fit([user_id_train,item_id_train],rating_train, epochs = 10 ,verbose=1, validation_split = 0.1)"
      ],
      "metadata": {
        "id": "SJzFW7-IBnwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test- evaluation\n",
        "loss = model.evaluate([user_id_test,item_id_test],rating_test)\n",
        "print(\"test loss:\",loss)"
      ],
      "metadata": {
        "id": "w9zYhI_ZHlYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = np.array([0])\n",
        "item_id = np.array([2])\n",
        "prediction = model.predict([user_id, item_id])\n",
        "print(\"prediction:\",prediction)\n",
        "#prediction: [[0.10810207]]\n",
        "\n",
        "user_id = np.array([0])\n",
        "item_id = np.array([3])\n",
        "prediction = model.predict([user_id, item_id])\n",
        "print(\"prediction:\",prediction)\n",
        "#prediction: [[0.11255766]]\n",
        "\n",
        "\n",
        "user_id = np.array([0])\n",
        "item_id = np.array([4])\n",
        "prediction = model.predict([user_id, item_id])\n",
        "print(\"prediction:\",prediction)\n",
        "# prediction: [[0.11840666]]\n",
        "\n",
        "user_id = np.array([0])\n",
        "item_id = np.array([5])\n",
        "prediction = model.predict([user_id, item_id])\n",
        "print(\"prediction:\",prediction)\n",
        "# prediction: [[0.11974955]]\n",
        "\n",
        "# en yüksek prediction değerleri önerilir"
      ],
      "metadata": {
        "id": "7o7hAi5QH48o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommendation system - Machine learning"
      ],
      "metadata": {
        "id": "r37ayxlKKhFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# MovieLens 100k verisini indir\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-100k/u.data'\n",
        "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "df = pd.read_csv(url, sep='\\t', names=columns)\n",
        "\n",
        "# Kullanıcı-Film Matrisi (Pivot Table) oluştur\n",
        "# Satırlar: Kullanıcılar, Sütunlar: Filmler\n",
        "user_item_matrix = df.pivot(index='user_id', columns='item_id', values='rating')\n",
        "\n",
        "# Eksik değerleri (izlenmeyen filmleri) 0 ile doldur\n",
        "user_item_matrix_filled = user_item_matrix.fillna(0)"
      ],
      "metadata": {
        "id": "zNytaQuNkdSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kullanıcılar arası benzerliği hesapla\n",
        "user_sim = cosine_similarity(user_item_matrix_filled)\n",
        "user_sim_df = pd.DataFrame(user_sim, index=user_item_matrix.index, columns=user_item_matrix.index)"
      ],
      "metadata": {
        "id": "sitN030rkkoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_rating(user_id, item_id):\n",
        "    # Eğer film veri setinde yoksa ortalama bir puan dön\n",
        "    if item_id not in user_item_matrix.columns:\n",
        "        return 2.5\n",
        "\n",
        "    # Hedef filmi izleyen kullanıcıları ve puanlarını al\n",
        "    item_ratings = user_item_matrix[item_id]\n",
        "    users_who_rated = item_ratings[item_ratings > 0].index\n",
        "\n",
        "    if len(users_who_rated) == 0:\n",
        "        return 2.5\n",
        "\n",
        "    # Hedef kullanıcının, bu filmi izleyen diğer kullanıcılarla olan benzerlikleri\n",
        "    weights = user_sim_df.loc[user_id, users_who_rated]\n",
        "    ratings = item_ratings[users_who_rated]\n",
        "\n",
        "    # Ağırlıklı ortalama: (Benzerlik * Puan) / Toplam Benzerlik\n",
        "    if weights.sum() == 0:\n",
        "        return 2.5\n",
        "\n",
        "    prediction = np.dot(weights, ratings) / weights.sum()\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "wTDiif1Skn2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bir tahmin\n",
        "print(predict_rating(1, 40))"
      ],
      "metadata": {
        "id": "0QuqCu4CksMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bir kullanıcı için en iyi önerileri sıralama\n",
        "def get_recommendations(target_user, top_n =5):\n",
        "  #kullanıcının henüz izlemediği filmleri bul\n",
        "  user_ratings = user_item_matrix.loc[target_user]\n",
        "  not_watched = user_ratings[user_ratings.isna()].index # veya user_ratings == 0\n",
        "\n",
        "  #izlemediği her film için bir öneri\n",
        "  pred = []\n",
        "  for movie_id in not_watched:\n",
        "    score = predict_rating(target_user,movie_id)\n",
        "    pred.append((movie_id,score))\n",
        "\n",
        "  #puanları büyükten küçüğe sırala\n",
        "  pred.sort(key=lambda x:x[1],reverse=True)\n",
        "  return pred[:top_n]"
      ],
      "metadata": {
        "id": "e9B4KedJk8Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recs = get_recommendations(1,5)\n",
        "for movie, score in recs:\n",
        "  print(f\"Film ID: {movie}, Tahmini Puan: {score}\")"
      ],
      "metadata": {
        "id": "c9s8QJvmmbWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Test için rastgele 100 örnek seçelim\n",
        "test_samples = df.sample(100)\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for idx, row in test_samples.iterrows():\n",
        "    actual = row['rating']\n",
        "    predicted = predict_rating(row['user_id'], row['item_id'])\n",
        "\n",
        "    y_true.append(actual)\n",
        "    y_pred.append(predicted)\n",
        "\n",
        "# RMSE Hesapla\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "print(f\"Modelin genel hata payı (RMSE): {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "cxVBL6GKnd4T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}